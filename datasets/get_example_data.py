# -*- coding: utf-8 -*-
"""cnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D0wYRLSFlS7ExoHUBASQSXxTaXsTHg-t
"""


import numpy as np
import pandas as pd
from multiplex_core import multiplexing_core 

##############################################################################
# Load example data trajectories to plot for the pipeline figure
##############################################################################


mc = multiplexing_core()

path1 = './construct_length_dataset_larger_range_14scale/construct_lengths_P300_P300.csv'
path2 = './construct_length_dataset_larger_range_14scale/construct_lengths_KDM5B_KDM5B.csv'

# parameters
Fr = 1
Nframes = 256
retrain = 5
ntraj = 2500
Nsamples = 5000
ntimes = 3000
witheld = 1000
test_size = 0
two_files = 1
seed = 42

# load the intensity and labels from the dataframes
if two_files:
    multiplexing_df1 = pd.read_csv(path1)
    multiplexing_df2 = pd.read_csv(path2)
    int_g1 = multiplexing_df1['green_int_mean'].values.reshape([ntraj,ntimes])    
    int_g2 = multiplexing_df2['green_int_mean'].values.reshape([ntraj,ntimes])    

    t = np.linspace(0,len(int_g1) - 1,len(int_g1))  #time vector in seconds
    labels = np.ones(int_g1.shape[0]*2)
    labels[:int_g1.shape[0]] = 0
    int_g = np.vstack((int_g1,int_g2))  #merge the files and then let it sort
    labels = labels
    # randomly shuffle the intensities and labels
    int_g, labels = mc.even_shuffle_sample(int_g, labels, samples=[int(Nsamples/2), int(Nsamples/2)], seed=seed)

else:    
    multiplexing_df = pd.read_csv(path1)
    int_g = multiplexing_df['green_int_mean'].values.reshape([ntraj,ntimes])
    labels = multiplexing_df['Classification'].values.reshape([ntraj,ntimes])[:,0]
    
    int_g, labels = mc.even_shuffle_sample(int_g, labels, samples=[int(Nsamples/2), int(Nsamples/2)], seed=seed)

# Slice the data to the approriate frames / frame interval
int_g = mc.slice_arr(int_g, Fr, Nframes)


# process the data, generate the autocorrelations
X_train, X_test, y_train, y_test, X_witheld, y_witheld, Acc_train, Acc_test, Acc_witheld = mc.process_data(int_g, labels, norm='train', seed=seed, witheld = witheld, test_size = test_size, include_acc = True )

# save example files
np.save('base_example_X_train',X_train)
np.save('base_example_y_train',y_train)
np.save('base_example_Acc_train',Acc_train)

