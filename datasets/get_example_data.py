# -*- coding: utf-8 -*-
"""cnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D0wYRLSFlS7ExoHUBASQSXxTaXsTHg-t
"""


import argparse
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
config = tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.4
sess = tf.Session(config=config)
tf.compat.v1.keras.backend.set_session(sess)


import logging
logging.getLogger('tensorflow').setLevel(logging.FATAL)

'''
if tf.test.gpu_device_name():
    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))
else:
    print("no connection to gpu")
'''
import numpy as np
import pandas as pd

from multiplex_core import multiplexing_core 

mc = multiplexing_core()

path1 = './construct_length_dataset_larger_range_14scale/construct_lengths_P300_P300.csv'
path2 = './construct_length_dataset_larger_range_14scale/construct_lengths_KDM5B_KDM5B.csv'

Fr = 1
Nframes = 256
retrain = 5
ntraj = 2500
Nsamples = 5000
ntimes = 3000
witheld = 1000
test_size = 0
two_files = 1
seed = 42

if two_files:
    multiplexing_df1 = pd.read_csv(path1)
    multiplexing_df2 = pd.read_csv(path2)
    int_g1 = multiplexing_df1['green_int_mean'].values.reshape([ntraj,ntimes])    
    int_g2 = multiplexing_df2['green_int_mean'].values.reshape([ntraj,ntimes])    

    t = np.linspace(0,len(int_g1) - 1,len(int_g1))  #time vector in seconds
    labels = np.ones(int_g1.shape[0]*2)
    labels[:int_g1.shape[0]] = 0
    int_g = np.vstack((int_g1,int_g2))  #merge the files and then let it sort
    labels = labels

    int_g, labels = mc.even_shuffle_sample(int_g, labels, samples=[int(Nsamples/2), int(Nsamples/2)], seed=seed)

else:    
    multiplexing_df = pd.read_csv(path1)
    int_g = multiplexing_df['green_int_mean'].values.reshape([ntraj,ntimes])
    labels = multiplexing_df['Classification'].values.reshape([ntraj,ntimes])[:,0]
    
    int_g, labels = mc.even_shuffle_sample(int_g, labels, samples=[int(Nsamples/2), int(Nsamples/2)], seed=seed)

# Slice the data
print(Fr)
print(Nframes)
int_g = mc.slice_arr(int_g, Fr, Nframes)

print(int_g.shape)
print(labels.shape)


X_train, X_test, y_train, y_test, X_witheld, y_witheld, Acc_train, Acc_test, Acc_witheld = mc.process_data(int_g, labels, norm='train', seed=seed, witheld = witheld, test_size = test_size, include_acc = True )

np.save('base_example_X_train',X_train)
np.save('base_example_y_train',y_train)
np.save('base_example_Acc_train',Acc_train)

